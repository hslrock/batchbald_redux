{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Experiment\n",
    "> Experiment using Repeated MNIST and BatchBALD vs BALD vs random sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook ties everything together and runs an AL loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment\n",
    "\n",
    "#import blackhc.project.script\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment\n",
    "\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from batchbald_redux import (\n",
    "    active_learning,\n",
    "    batchbald,\n",
    "    consistent_mc_dropout,\n",
    "    joint_entropy,\n",
    "    repeated_mnist,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define our Bayesian CNN model that we will use to train MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment\n",
    "\n",
    "\n",
    "class BayesianCNN(consistent_mc_dropout.BayesianModule):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv1_drop = consistent_mc_dropout.ConsistentMCDropout2d()\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.conv2_drop = consistent_mc_dropout.ConsistentMCDropout2d()\n",
    "        self.fc1 = nn.Linear(1024, 128)\n",
    "        self.fc1_drop = consistent_mc_dropout.ConsistentMCDropout()\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def mc_forward_impl(self, input: torch.Tensor):\n",
    "        input = F.relu(F.max_pool2d(self.conv1_drop(self.conv1(input)), 2))\n",
    "        input = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(input)), 2))\n",
    "        input = input.view(-1, 1024)\n",
    "        input = F.relu(self.fc1_drop(self.fc1(input)))\n",
    "        input = self.fc2(input)\n",
    "        input = F.log_softmax(input, dim=1)\n",
    "\n",
    "        return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 20\n",
    "VAL_SIZE = 300\n",
    "MONITOR_SIZE=300\n",
    "POOL_SIZE = 60000 - TRAIN_SIZE - VAL_SIZE -MONITOR_SIZE\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "            [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "        )\n",
    "\n",
    "mnist_train = MNIST(\".\", train=True, download=True, transform=transform)\n",
    "mnist_test = MNIST(\".\", train=False, download=True, transform=transform)\n",
    "\n",
    "\n",
    "train_set, val_set, pool_set,monitor_set = random_split(\n",
    "    mnist_train, [TRAIN_SIZE, VAL_SIZE, POOL_SIZE,MONITOR_SIZE]\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_set, batch_size=TRAIN_SIZE, shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(dataset=val_set, batch_size=VAL_SIZE, shuffle=True)\n",
    "pool_loader = DataLoader(\n",
    "    dataset=pool_set, batch_size=POOL_SIZE, shuffle=True\n",
    ")\n",
    "\n",
    "monitor_loader = DataLoader(\n",
    "    dataset=pool_set, batch_size=MONITOR_SIZE, shuffle=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=mnist_test, batch_size=312, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab our dataset, we'll use Repeated-MNIST. We will acquire to samples for each class for our initial training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment\n",
    "\n",
    "train_dataset, test_dataset = repeated_mnist.create_repeated_MNIST_dataset(num_repetitions=1, add_noise=False)\n",
    "train_dataset,monitor_set = random_split(\n",
    "    train_dataset, [59900,100]\n",
    ")\n",
    "num_initial_samples = 20\n",
    "num_classes = 10\n",
    "\n",
    "initial_samples = active_learning.get_balanced_sample_indices(\n",
    "    repeated_mnist.get_targets(train_dataset), num_classes=num_classes, n_per_digit=num_initial_samples / num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59900"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we are going to take two shortcuts that will reduce the performance:\n",
    "* we discard most of the training set and only keep 20k samples; and\n",
    "* we don't implement early stopping or epoch-wise training.\n",
    "\n",
    "Instead, we always train by drawing 24576 many samples from the training set. This will overfit in the beginning and underfit later, but it still is sufficient to achieve 90% accuracy with 105 samples in the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_cuda: True\n"
     ]
    }
   ],
   "source": [
    "# experiment\n",
    "max_training_samples = 150\n",
    "acquisition_batch_size = 5\n",
    "num_inference_samples = 100\n",
    "num_test_inference_samples = 5\n",
    "num_samples = 100000\n",
    "\n",
    "test_batch_size = 512\n",
    "batch_size = 64\n",
    "scoring_batch_size = 128\n",
    "training_iterations = 4096 * 6\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "print(f\"use_cuda: {use_cuda}\")\n",
    "\n",
    "device = \"cuda\" if use_cuda else \"cpu\"\n",
    "\n",
    "kwargs = {\"num_workers\": 1, \"pin_memory\": True} if use_cuda else {}\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "active_learning_data = active_learning.ActiveLearningData(train_dataset)\n",
    "\n",
    "# Split off the initial samples first.\n",
    "active_learning_data.acquire(initial_samples)\n",
    "\n",
    "# THIS REMOVES MOST OF THE POOL DATA. UNCOMMENT THIS TO TAKE ALL UNLABELLED DATA INTO ACCOUNT!\n",
    "#active_learning_data.extract_dataset_from_pool(40000)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    active_learning_data.training_dataset,\n",
    "    sampler=active_learning.RandomFixedLengthSampler(active_learning_data.training_dataset, training_iterations),\n",
    "    batch_size=batch_size,\n",
    "    **kwargs,\n",
    ")\n",
    "\n",
    "pool_loader = torch.utils.data.DataLoader(\n",
    "    active_learning_data.pool_dataset, batch_size=scoring_batch_size, shuffle=False, **kwargs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1c207co8) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 11048... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">icy-valley-1</strong>: <a href=\"https://wandb.ai/hslrock/ActiveLearning_1124/runs/1c207co8\" target=\"_blank\">https://wandb.ai/hslrock/ActiveLearning_1124/runs/1c207co8</a><br/>\n",
       "Find logs at: <code>.\\wandb\\run-20211124_223626-1c207co8\\logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1c207co8). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hslrock/ActiveLearning_1124/runs/wpyhwj2i\" target=\"_blank\">twilight-dragon-2</a></strong> to <a href=\"https://wandb.ai/hslrock/ActiveLearning_1124\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19cd07f264e34164a40da47b1a52f660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Set Size:  13%|#3        | 20/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/384 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Acquisition Set:   0%|          | 0/156 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/19880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/19880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset indices:  [11504 16265 45267 22626 58655]\n",
      "Scores:  [1.3371315741670893, 1.2840991833492765, 1.259585630032177, 1.247872067496476, 1.2430764680138355]\n",
      "Labels:  tensor([2, 6, 5, 6, 9])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/384 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Acquisition Set:   0%|          | 0/156 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/19875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/19875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset indices:  [47390 10059 40329  1000 25137]\n",
      "Scores:  [1.3126765715210704, 1.2899330328994778, 1.2839473608201857, 1.271654106883802, 1.267077879773238]\n",
      "Labels:  tensor([7, 3, 3, 3, 2])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/384 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Acquisition Set:   0%|          | 0/156 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/19870 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/19870 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset indices:  [51687 20636 13466 18147 42797]\n",
      "Scores:  [1.3697880689368809, 1.3375052365825908, 1.329340756522325, 1.322733408558638, 1.3198637128780903]\n",
      "Labels:  tensor([5, 2, 3, 3, 3])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/384 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Acquisition Set:   0%|          | 0/156 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/19865 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/19865 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset indices:  [55396 13127 47377  4079 19955]\n",
      "Scores:  [1.3310214270691543, 1.3019635570317005, 1.28756920713807, 1.279090520821545, 1.275343704621409]\n",
      "Labels:  tensor([6, 0, 0, 4, 5])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/384 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Acquisition Set:   0%|          | 0/156 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/19860 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/19860 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset indices:  [53486 55131 20808 56443  7731]\n",
      "Scores:  [1.330598704211786, 1.303957533518792, 1.302388199960565, 1.2810615329865356, 1.27600770829741]\n",
      "Labels:  tensor([5, 8, 5, 3, 8])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/384 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Acquisition Set:   0%|          | 0/156 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/19855 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/19855 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset indices:  [25693 16074   252 17257 54913]\n",
      "Scores:  [1.3971341488951907, 1.3190735995908967, 1.3125291360637168, 1.3120757085992214, 1.2892533574609386]\n",
      "Labels:  tensor([9, 2, 4, 8, 0])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/384 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Acquisition Set:   0%|          | 0/156 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/19850 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/19850 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset indices:  [22420  4098 42433 41469  3580]\n",
      "Scores:  [1.3753962463348717, 1.3592637069532345, 1.3115099819548446, 1.308221824362246, 1.2973480618696858]\n",
      "Labels:  tensor([0, 9, 0, 4, 0])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/384 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Acquisition Set:   0%|          | 0/156 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/19845 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/19845 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset indices:  [50678 32447  6296 53170 22518]\n",
      "Scores:  [1.3373361807478488, 1.278140804499416, 1.2682258135163482, 1.2578451633772576, 1.2462278535485924]\n",
      "Labels:  tensor([2, 2, 9, 8, 4])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/384 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Acquisition Set:   0%|          | 0/155 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/19840 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/19840 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset indices:  [54765 32899  5526 57516 45945]\n",
      "Scores:  [1.2704354553099289, 1.2627667336384292, 1.2458695930591912, 1.2411978507607926, 1.2019321650581771]\n",
      "Labels:  tensor([4, 5, 5, 8, 8])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/384 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Acquisition Set:   0%|          | 0/155 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/19835 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/19835 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset indices:  [42854 23377 39908 50881 25810]\n",
      "Scores:  [1.3131297043289765, 1.2673920631047837, 1.2667417101898082, 1.2580927065328944, 1.256854244353568]\n",
      "Labels:  tensor([6, 7, 8, 1, 6])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/384 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Acquisition Set:   0%|          | 0/155 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/19830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/19830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset indices:  [26075 42067  6337 23716 46436]\n",
      "Scores:  [1.3621845313869982, 1.3410256819863273, 1.3219267223569886, 1.3177197742707314, 1.2987949702224544]\n",
      "Labels:  tensor([0, 5, 3, 5, 8])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/384 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=\"ActiveLearning_1124\")\n",
    "wandb.run.name = 'BALD_MNIST_200001124'\n",
    "wandb.run.save()\n",
    "\n",
    "\n",
    "# Run experiment\n",
    "test_accs = []\n",
    "test_loss = []\n",
    "added_indices = []\n",
    "\n",
    "pbar = tqdm(initial=len(active_learning_data.training_dataset), total=max_training_samples, desc=\"Training Set Size\")\n",
    "epoch=0\n",
    "model = BayesianCNN(num_classes).to(device=device)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "while True:\n",
    "\n",
    "    epoch+=1\n",
    "    model.train()\n",
    "    train_loss=0\n",
    "    # Train\n",
    "    for data, target in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "        data = data.to(device=device)\n",
    "        target = target.to(device=device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        prediction = model(data, 1).squeeze(1)\n",
    "        loss = F.nll_loss(prediction, target)\n",
    "        train_loss+=loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                                                   \n",
    "    train_loss /= len(train_loader)\n",
    "    # Test\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(test_loader, desc=\"Testing\", leave=False):\n",
    "            data = data.to(device=device)\n",
    "            target = target.to(device=device)\n",
    "\n",
    "            prediction = torch.logsumexp(model(data, num_test_inference_samples), dim=1) - math.log(\n",
    "                num_test_inference_samples\n",
    "            )\n",
    "            loss += F.nll_loss(prediction, target, reduction=\"sum\")\n",
    "        \n",
    "            prediction = prediction.max(1)[1]\n",
    "            correct += prediction.eq(target.view_as(prediction)).sum().item()\n",
    "\n",
    "    loss /= len(test_loader.dataset)\n",
    "\n",
    "    percentage_correct = 100.0 * correct / len(test_loader.dataset)\n",
    "\n",
    "\n",
    "                                                   \n",
    "    if len(active_learning_data.training_dataset) >= max_training_samples:\n",
    "        break\n",
    "\n",
    "    # Acquire pool predictions\n",
    "                                                   \n",
    "    acquir_start=time.time()\n",
    "    N = len(active_learning_data.pool_dataset)\n",
    "    logits_N_K_C = torch.empty((N, num_inference_samples, num_classes), dtype=torch.double, pin_memory=use_cuda)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        \n",
    "        for i, (data, _) in enumerate(tqdm(pool_loader, desc=\"Evaluating Acquisition Set\", leave=False)):\n",
    "            data = data.to(device=device)\n",
    "\n",
    "            lower = i * pool_loader.batch_size\n",
    "            upper = min(lower + pool_loader.batch_size, N)\n",
    "            logits_N_K_C[lower:upper].copy_(model(data, num_inference_samples).double(), non_blocking=True)\n",
    "\n",
    "            \n",
    "    with torch.no_grad():\n",
    "#         candidate_batch = batchbald.get_batchbald_batch(\n",
    "#             logits_N_K_C, acquisition_batch_size, num_samples, dtype=torch.double, device=device\n",
    "#         )\n",
    "        candidate_batch = batchbald.get_bald_batch(\n",
    "            logits_N_K_C, acquisition_batch_size, dtype=torch.double, device=device\n",
    "        )\n",
    "                                                   \n",
    "    acquire_end=acquir_start-time.time()\n",
    "    wandb.log({\"Epoch\":epoch,\n",
    "               \"Num_Pool\":len(pool_loader)\n",
    "               \"Num_Train\":len(training_dataset)\n",
    "               \"Test Loss\": loss,\n",
    "               'Train Loss': train_loss,\n",
    "              \"Test Accuracy\":percentage_correct,\n",
    "               \"Query Time\":-acquire_end})\n",
    "\n",
    "                                                   \n",
    "    targets = repeated_mnist.get_targets(active_learning_data.pool_dataset)\n",
    "    dataset_indices = active_learning_data.get_dataset_indices(candidate_batch.indices)\n",
    "\n",
    "    print(\"Dataset indices: \", dataset_indices)\n",
    "    print(\"Scores: \", candidate_batch.scores)\n",
    "    print(\"Labels: \", targets[candidate_batch.indices])\n",
    "\n",
    "    active_learning_data.acquire(candidate_batch.indices)\n",
    "    added_indices.append(dataset_indices)\n",
    "    pbar.update(len(dataset_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.plot(np.arange(num_initial_samples, max_training_samples + 1, acquisition_batch_size), test_accs)\n",
    "plt.xlabel(\"# training samples\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.hlines(90, 20, 150, linestyles=\"dashed\", color=\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97ee419609b24e4db3598b1766ccad8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Acquisition Set:   0%|          | 0/156 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'N' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HYUNSE~1\\AppData\\Local\\Temp/ipykernel_17492/3442480421.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mlower\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mpool_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mupper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlower\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpool_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mlogits_N_K_C\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_inference_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'N' is not defined"
     ]
    }
   ],
   "source": [
    "model = BayesianCNN(num_classes).to(device=device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    for i, (data, _) in enumerate(tqdm(pool_loader, desc=\"Evaluating Acquisition Set\", leave=False)):\n",
    "        data = data.to(device=device)\n",
    "\n",
    "        lower = i * pool_loader.batch_size\n",
    "        upper = min(lower + pool_loader.batch_size, N)\n",
    "        logits_N_K_C[lower:upper].copy_(model(data, num_inference_samples).double(), non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
